{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language_model_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdXEo1I1cVwkNn7n8B+FpV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hardikkamboj/Implementations-in-Python/blob/main/NLP/language%20models/Language_model_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsXFPwx9sMzd"
      },
      "source": [
        "from nltk.corpus import reuters\r\n",
        "from nltk import bigrams, trigrams,word_tokenize\r\n",
        "from collections import Counter, defaultdict\r\n",
        "from tqdm import tqdm\r\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov496RU5s0Tl",
        "outputId": "355cfa50-5f65-4106-f32e-06367d9a62cc"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('reuters')\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "o-e5w-1JskAB",
        "outputId": "f0630ed7-f511-47b3-ad83-4951db32be5d"
      },
      "source": [
        "sents = reuters.sents()\r\n",
        "' '.join(sents[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPAN RIFT Mounting trade friction between the U . S . And Japan has raised fears among many of Asia ' s exporting nations that the row could inflict far - reaching economic damage , businessmen and officials said .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XADroKIOk7h",
        "outputId": "ea80fe42-39f5-4699-fc89-349ebe7bfb05"
      },
      "source": [
        "# to understand what are trigrams.\n",
        "temp = ['Hello everyone my name is Hardik and am from India','Hello there very nice to meet you']\n",
        "\n",
        "for sent in temp:\n",
        "  n_grams = trigrams(word_tokenize(sent),pad_right=True, pad_left=True) # using padding we can add the first couple of words, and the last words too.\n",
        "  for grams in n_grams:\n",
        "    print(grams)\n",
        "  print('')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 'Hello')\n",
            "(None, 'Hello', 'everyone')\n",
            "('Hello', 'everyone', 'my')\n",
            "('everyone', 'my', 'name')\n",
            "('my', 'name', 'is')\n",
            "('name', 'is', 'Hardik')\n",
            "('is', 'Hardik', 'and')\n",
            "('Hardik', 'and', 'am')\n",
            "('and', 'am', 'from')\n",
            "('am', 'from', 'India')\n",
            "('from', 'India', None)\n",
            "('India', None, None)\n",
            "\n",
            "(None, None, 'Hello')\n",
            "(None, 'Hello', 'there')\n",
            "('Hello', 'there', 'very')\n",
            "('there', 'very', 'nice')\n",
            "('very', 'nice', 'to')\n",
            "('nice', 'to', 'meet')\n",
            "('to', 'meet', 'you')\n",
            "('meet', 'you', None)\n",
            "('you', None, None)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmo0vNYWLxmb"
      },
      "source": [
        "**Why are we using defaultdict instead of simple dict?** <br> \n",
        "Usually, a Python dictionary throws a KeyError if you try to get an item with a key that is not currently in the dictionary. The defaultdict in contrast will simply create any items that you try to access (provided of course they do not exist yet). To create such a \"default\" item, it calls the function object that you pass to the constructor (more precisely, it's an arbitrary \"callable\" object, which includes function and type objects). For the first example, default items are created using int(), which will return the integer object 0. For the second example, default items are created using list(), which returns a new empty list object.\n",
        "(taken from stackoverflow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7wo_n2ZZmkR",
        "outputId": "e2027d50-e926-4723-8e0e-e557fbe9180b"
      },
      "source": [
        "#now since we know what trigrans are, lets create a language model for this. \n",
        "\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "for sentence in tqdm(temp):\n",
        "    for w1, w2, w3 in trigrams(word_tokenize(sentence), pad_right=True, pad_left=True):\n",
        "        model[(w1, w2)][w3] += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 1969.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHoBYby6vT3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92cb102e-25e7-48c9-9c7a-d5e2b27f5b14"
      },
      "source": [
        "for key in model:\r\n",
        "  print(key)\r\n",
        "  print(model[key])\r\n",
        "  print(' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None)\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec9d8>, {'Hello': 2})\n",
            " \n",
            "(None, 'Hello')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec840>, {'everyone': 1, 'there': 1})\n",
            " \n",
            "('Hello', 'everyone')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec950>, {'my': 1})\n",
            " \n",
            "('everyone', 'my')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec8c8>, {'name': 1})\n",
            " \n",
            "('my', 'name')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec7b8>, {'is': 1})\n",
            " \n",
            "('name', 'is')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec730>, {'Hardik': 1})\n",
            " \n",
            "('is', 'Hardik')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec6a8>, {'and': 1})\n",
            " \n",
            "('Hardik', 'and')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec620>, {'am': 1})\n",
            " \n",
            "('and', 'am')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec598>, {'from': 1})\n",
            " \n",
            "('am', 'from')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec510>, {'India': 1})\n",
            " \n",
            "('from', 'India')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec488>, {None: 1})\n",
            " \n",
            "('India', None)\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec378>, {None: 1})\n",
            " \n",
            "('Hello', 'there')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec400>, {'very': 1})\n",
            " \n",
            "('there', 'very')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec2f0>, {'nice': 1})\n",
            " \n",
            "('very', 'nice')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec268>, {'to': 1})\n",
            " \n",
            "('nice', 'to')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec1e0>, {'meet': 1})\n",
            " \n",
            "('to', 'meet')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec158>, {'you': 1})\n",
            " \n",
            "('meet', 'you')\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec0d0>, {None: 1})\n",
            " \n",
            "('you', None)\n",
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7fed791ec048>, {None: 1})\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcewvAGUsckr"
      },
      "source": [
        "# Let's transform the counts to probabilities\r\n",
        "for w1_w2 in model:\r\n",
        "    total_count = float(sum(model[w1_w2].values()))\r\n",
        "    for w3 in model[w1_w2]:\r\n",
        "        model[w1_w2][w3] /= total_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxTALhilySeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b275d33-5079-4437-a671-868f341d533c"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>>,\n",
              "            {('Hardik',\n",
              "              'and'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'am': 1.0}),\n",
              "             ('Hello',\n",
              "              'everyone'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'my': 1.0}),\n",
              "             ('Hello',\n",
              "              'there'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'very': 1.0}),\n",
              "             ('India',\n",
              "              None): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {None: 1.0}),\n",
              "             ('am',\n",
              "              'from'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'India': 1.0}),\n",
              "             ('and',\n",
              "              'am'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'from': 1.0}),\n",
              "             ('everyone',\n",
              "              'my'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'name': 1.0}),\n",
              "             ('from',\n",
              "              'India'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {None: 1.0}),\n",
              "             ('is',\n",
              "              'Hardik'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'and': 1.0}),\n",
              "             ('meet',\n",
              "              'you'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {None: 1.0}),\n",
              "             ('my',\n",
              "              'name'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'is': 1.0}),\n",
              "             ('name',\n",
              "              'is'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'Hardik': 1.0}),\n",
              "             ('nice',\n",
              "              'to'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'meet': 1.0}),\n",
              "             ('there',\n",
              "              'very'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'nice': 1.0}),\n",
              "             ('to',\n",
              "              'meet'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'you': 1.0}),\n",
              "             ('very',\n",
              "              'nice'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'to': 1.0}),\n",
              "             ('you',\n",
              "              None): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {None: 1.0}),\n",
              "             (None,\n",
              "              'Hello'): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'everyone': 0.5,\n",
              "                          'there': 0.5}),\n",
              "             (None,\n",
              "              None): defaultdict(<function __main__.<lambda>.<locals>.<lambda>>, {'Hello': 1.0})})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtOr_Ut2aMFy"
      },
      "source": [
        "Now our language model is ready for our temperary sentence, lets see how we can use this to make predictions - \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9agRrjFeaaFp",
        "outputId": "0b7020c7-e2e0-48fb-9125-32192b4840eb"
      },
      "source": [
        "dict(model[('Hello','everyone')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'my': 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNxQcggQaghP",
        "outputId": "8703fec1-ba3c-42b5-9a2f-a14badbd1fda"
      },
      "source": [
        "dict(model[('my','name')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'is': 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TieFjVVsalGa"
      },
      "source": [
        "We can see how the model has learnt from the sentence that we provided and is learning from them. \n",
        "The model is able to predict the next word for sentences like 'Hello everyone'-> my and 'my name' -> 'is' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lioWBLpebJ7U"
      },
      "source": [
        "But it won't be able to predict the word combinations that doesn't occur in the word corpus -  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow_poabtbR_c",
        "outputId": "a8dae697-e7f6-4ca0-ab48-2110aba5b43b"
      },
      "source": [
        "dict(model[('the','weather')]) # it predicts nothing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwBgAHYXa8Cz"
      },
      "source": [
        "## Now lets try building this model on a large corpus, so that we can get relatively more meaningful predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ScWx1_m0Fpv",
        "outputId": "9504520e-67cc-487a-9b8d-419376bcebc5"
      },
      "source": [
        "model = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "\r\n",
        "# Count frequency of co-occurance  \r\n",
        "for sentence in tqdm(reuters.sents()):\r\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "        model[(w1, w2)][w3] += 1\r\n",
        " \r\n",
        "# Let's transform the counts to probabilities\r\n",
        "for w1_w2 in model:\r\n",
        "    total_count = float(sum(model[w1_w2].values()))\r\n",
        "    for w3 in model[w1_w2]:\r\n",
        "        model[w1_w2][w3] /= total_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54716/54716 [00:12<00:00, 4260.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgOkdbUv0TKn",
        "outputId": "851590bd-2cb7-47ce-e9c1-9138ffb7b3b2"
      },
      "source": [
        "ans = dict(model['I','am'])\r\n",
        "sorted(ans.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sure', 0.15384615384615385),\n",
              " ('not', 0.1076923076923077),\n",
              " ('confident', 0.07692307692307693),\n",
              " ('convinced', 0.06153846153846154),\n",
              " ('concerned', 0.046153846153846156),\n",
              " ('afraid', 0.046153846153846156),\n",
              " ('deeply', 0.046153846153846156),\n",
              " ('committed', 0.03076923076923077),\n",
              " ('of', 0.03076923076923077),\n",
              " ('speculating', 0.03076923076923077),\n",
              " ('optimistic', 0.03076923076923077),\n",
              " ('encouraged', 0.015384615384615385),\n",
              " ('more', 0.015384615384615385),\n",
              " ('talking', 0.015384615384615385),\n",
              " ('pleased', 0.015384615384615385),\n",
              " (',', 0.015384615384615385),\n",
              " ('happy', 0.015384615384615385),\n",
              " ('for', 0.015384615384615385),\n",
              " ('against', 0.015384615384615385),\n",
              " ('very', 0.015384615384615385),\n",
              " ('cautiously', 0.015384615384615385),\n",
              " ('sceptical', 0.015384615384615385),\n",
              " ('hopeful', 0.015384615384615385),\n",
              " ('now', 0.015384615384615385),\n",
              " ('unable', 0.015384615384615385),\n",
              " ('expecting', 0.015384615384615385),\n",
              " ('astonished', 0.015384615384615385),\n",
              " ('joining', 0.015384615384615385),\n",
              " ('on', 0.015384615384615385),\n",
              " ('inclined', 0.015384615384615385),\n",
              " ('referring', 0.015384615384615385),\n",
              " ('looking', 0.015384615384615385),\n",
              " ('really', 0.015384615384615385)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8IAQF5C0cVQ",
        "outputId": "549ee427-4396-4170-841b-e93cd33431d0"
      },
      "source": [
        "ans = dict(model[None,'the'])\r\n",
        "sorted(ans.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('loan', 0.18181818181818182),\n",
              " ('second', 0.09090909090909091),\n",
              " ('price', 0.09090909090909091),\n",
              " ('increase', 0.09090909090909091),\n",
              " ('reorganization', 0.09090909090909091),\n",
              " ('restatement', 0.09090909090909091),\n",
              " ('quake', 0.09090909090909091),\n",
              " ('proposed', 0.09090909090909091),\n",
              " ('acqustion', 0.09090909090909091),\n",
              " ('company', 0.09090909090909091)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuebNWER1E7d",
        "outputId": "4dfe17d0-e057-4df2-f1bb-dd0c024daaba"
      },
      "source": [
        "# generating text \r\n",
        "\r\n",
        "import random\r\n",
        "\r\n",
        "# starting words\r\n",
        "text = [\"today\", \"the\"]\r\n",
        "sentence_finished = False\r\n",
        " \r\n",
        "while not sentence_finished:\r\n",
        "  # select a random probability threshold  \r\n",
        "  r = random.random()\r\n",
        "  accumulator = 0.01 # the minimum probability for a word to be added in text\r\n",
        "\r\n",
        "  for word in model[tuple(text[-2:])].keys():\r\n",
        "      accumulator += model[tuple(text[-2:])][word]\r\n",
        "      # select words that are above the probability threshold\r\n",
        "      if accumulator >= r:\r\n",
        "          text.append(word)\r\n",
        "          break\r\n",
        "\r\n",
        "  if text[-2:] == [None, None]:\r\n",
        "      sentence_finished = True\r\n",
        " \r\n",
        "print (' '.join([t for t in text if t]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "today the overseas operations and might decide to respect pledges on monetary policies behind them , delegates said .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PIIFurJcaFw"
      },
      "source": [
        "## Saving the dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "R35TPt-7cnRe",
        "outputId": "7d770fdc-6d94-43c0-a9d4-d06e07f28452"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(dict(model), open(\"save.p\", \"wb\"))  # save it into a file named save.p"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-5f3700815c20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"save.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save it into a file named save.p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object '<lambda>.<locals>.<lambda>'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ4cucp_cu2-"
      },
      "source": [
        "d = dict(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCzid9iGd8jG",
        "outputId": "775c7409-fdf6-4675-ec36-7b6bf5617228"
      },
      "source": [
        "dict(d[('I','am')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': 0.015384615384615385,\n",
              " 'afraid': 0.046153846153846156,\n",
              " 'against': 0.015384615384615385,\n",
              " 'astonished': 0.015384615384615385,\n",
              " 'cautiously': 0.015384615384615385,\n",
              " 'committed': 0.03076923076923077,\n",
              " 'concerned': 0.046153846153846156,\n",
              " 'confident': 0.07692307692307693,\n",
              " 'convinced': 0.06153846153846154,\n",
              " 'deeply': 0.046153846153846156,\n",
              " 'encouraged': 0.015384615384615385,\n",
              " 'expecting': 0.015384615384615385,\n",
              " 'for': 0.015384615384615385,\n",
              " 'happy': 0.015384615384615385,\n",
              " 'hopeful': 0.015384615384615385,\n",
              " 'inclined': 0.015384615384615385,\n",
              " 'joining': 0.015384615384615385,\n",
              " 'looking': 0.015384615384615385,\n",
              " 'more': 0.015384615384615385,\n",
              " 'not': 0.1076923076923077,\n",
              " 'now': 0.015384615384615385,\n",
              " 'of': 0.03076923076923077,\n",
              " 'on': 0.015384615384615385,\n",
              " 'optimistic': 0.03076923076923077,\n",
              " 'pleased': 0.015384615384615385,\n",
              " 'really': 0.015384615384615385,\n",
              " 'referring': 0.015384615384615385,\n",
              " 'sceptical': 0.015384615384615385,\n",
              " 'speculating': 0.03076923076923077,\n",
              " 'sure': 0.15384615384615385,\n",
              " 'talking': 0.015384615384615385,\n",
              " 'unable': 0.015384615384615385,\n",
              " 'very': 0.015384615384615385}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhehx1yWd_6V",
        "outputId": "d81d9bdb-3066-4343-cdaf-0cc911f6cbec"
      },
      "source": [
        "!pip install dill"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (0.3.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsH7BdNKgFvT"
      },
      "source": [
        "import dill # doesn't come with default anaconda. Install with \"conda install dill\"\n",
        "\n",
        "dill_file = open(\"model.pickle\", \"wb\")\n",
        "dill_file.write(dill.dumps(model))\n",
        "dill_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o36fWXXrqJ7t"
      },
      "source": [
        "dill_file = open(\"Q.pickle\", \"wb\")\n",
        "dill_file.write(dill.dumps(model))\n",
        "dill_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO1Lwe2Ag03T"
      },
      "source": [
        "file = open('/content/model.pickle', 'rb')\n",
        "loaded_model = dill.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idv9QAq-lv4Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}