{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language_model_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCmiOeT4AFYraMq+U4FUKH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hardikkamboj/Implementations-in-Python/blob/main/NLP/language%20models/Language_model_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsXFPwx9sMzd"
      },
      "source": [
        "from nltk.corpus import reuters\r\n",
        "from nltk import bigrams, trigrams,word_tokenize\r\n",
        "from collections import Counter, defaultdict\r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov496RU5s0Tl",
        "outputId": "b5e59305-48a5-4fac-dd57-2a66560bd407"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('reuters')\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "o-e5w-1JskAB",
        "outputId": "c36f1310-dee6-4b4e-e4ae-50c015050bd1"
      },
      "source": [
        "sents = reuters.sents()\r\n",
        "' '.join(sents[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPAN RIFT Mounting trade friction between the U . S . And Japan has raised fears among many of Asia ' s exporting nations that the row could inflict far - reaching economic damage , businessmen and officials said .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8Jr41W0t5Z_",
        "outputId": "8be9fdaf-92d7-49f4-81e3-3741e5c431ed"
      },
      "source": [
        "# lets understand trigrams from a sentence\r\n",
        "temp = ['Hello everyone my name is Hardik and am from India','Hello there very nice to meet you']\r\n",
        "tokenized_corpus = []\r\n",
        "for sentence in temp:\r\n",
        "  tokenized_corpus.append(word_tokenize(sentence))\r\n",
        "\r\n",
        "n_grams = trigrams(tokens,pad_right=True, pad_left=True)\r\n",
        "\r\n",
        "for grams in n_grams :\r\n",
        "   print(grams)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 'Hello')\n",
            "(None, 'Hello', 'everyone,')\n",
            "('Hello', 'everyone,', 'my')\n",
            "('everyone,', 'my', 'name')\n",
            "('my', 'name', 'is')\n",
            "('name', 'is', 'Hardik,')\n",
            "('is', 'Hardik,', 'and')\n",
            "('Hardik,', 'and', 'am')\n",
            "('and', 'am', 'from')\n",
            "('am', 'from', 'India')\n",
            "('from', 'India', None)\n",
            "('India', None, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6eR-dtzsWHq"
      },
      "source": [
        "# Create a placeholder for model\r\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "\r\n",
        "# Count frequency of co-occurance  \r\n",
        "for sentence in n_grams:\r\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "        model[(w1, w2)][w3] += 1\r\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHoBYby6vT3p"
      },
      "source": [
        "for key in model:\r\n",
        "  print(key)\r\n",
        "  print(model[key])\r\n",
        "  print(' ')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcewvAGUsckr"
      },
      "source": [
        "# Let's transform the counts to probabilities\r\n",
        "for w1_w2 in model:\r\n",
        "    total_count = float(sum(model[w1_w2].values()))\r\n",
        "    for w3 in model[w1_w2]:\r\n",
        "        model[w1_w2][w3] /= total_coun"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxTALhilySeD"
      },
      "source": [
        "for t in model:\r\n",
        "  print(t)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOz4H68szitO",
        "outputId": "d2a06210-1e39-4e99-dd6e-645cad222aac"
      },
      "source": [
        "model"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>>, {})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ScWx1_m0Fpv",
        "outputId": "e393efc3-2894-437a-c953-1d72e101a718"
      },
      "source": [
        "model = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "\r\n",
        "# Count frequency of co-occurance  \r\n",
        "for sentence in tqdm(reuters.sents()):\r\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "        model[(w1, w2)][w3] += 1\r\n",
        " \r\n",
        "# Let's transform the counts to probabilities\r\n",
        "for w1_w2 in model:\r\n",
        "    total_count = float(sum(model[w1_w2].values()))\r\n",
        "    for w3 in model[w1_w2]:\r\n",
        "        model[w1_w2][w3] /= total_count"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54716/54716 [00:09<00:00, 6039.22it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgOkdbUv0TKn",
        "outputId": "8c4fb958-9359-4629-839f-c7d38924488d"
      },
      "source": [
        "ans = dict(model['I','am'])\r\n",
        "sorted(ans.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sure', 0.15384615384615385),\n",
              " ('not', 0.1076923076923077),\n",
              " ('confident', 0.07692307692307693),\n",
              " ('convinced', 0.06153846153846154),\n",
              " ('concerned', 0.046153846153846156),\n",
              " ('afraid', 0.046153846153846156),\n",
              " ('deeply', 0.046153846153846156),\n",
              " ('committed', 0.03076923076923077),\n",
              " ('of', 0.03076923076923077),\n",
              " ('speculating', 0.03076923076923077),\n",
              " ('optimistic', 0.03076923076923077),\n",
              " ('encouraged', 0.015384615384615385),\n",
              " ('more', 0.015384615384615385),\n",
              " ('talking', 0.015384615384615385),\n",
              " ('pleased', 0.015384615384615385),\n",
              " (',', 0.015384615384615385),\n",
              " ('happy', 0.015384615384615385),\n",
              " ('for', 0.015384615384615385),\n",
              " ('against', 0.015384615384615385),\n",
              " ('very', 0.015384615384615385),\n",
              " ('cautiously', 0.015384615384615385),\n",
              " ('sceptical', 0.015384615384615385),\n",
              " ('hopeful', 0.015384615384615385),\n",
              " ('now', 0.015384615384615385),\n",
              " ('unable', 0.015384615384615385),\n",
              " ('expecting', 0.015384615384615385),\n",
              " ('astonished', 0.015384615384615385),\n",
              " ('joining', 0.015384615384615385),\n",
              " ('on', 0.015384615384615385),\n",
              " ('inclined', 0.015384615384615385),\n",
              " ('referring', 0.015384615384615385),\n",
              " ('looking', 0.015384615384615385),\n",
              " ('really', 0.015384615384615385)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8IAQF5C0cVQ",
        "outputId": "138c1103-692a-466e-9de8-6c6ea8f3c4b0"
      },
      "source": [
        "ans = dict(model[None,'the'])\r\n",
        "sorted(ans.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('loan', 0.18181818181818182),\n",
              " ('second', 0.09090909090909091),\n",
              " ('price', 0.09090909090909091),\n",
              " ('increase', 0.09090909090909091),\n",
              " ('reorganization', 0.09090909090909091),\n",
              " ('restatement', 0.09090909090909091),\n",
              " ('quake', 0.09090909090909091),\n",
              " ('proposed', 0.09090909090909091),\n",
              " ('acqustion', 0.09090909090909091),\n",
              " ('company', 0.09090909090909091)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuebNWER1E7d",
        "outputId": "6e0d9b94-d36b-426d-b702-96f401482cd5"
      },
      "source": [
        "# generating text \r\n",
        "\r\n",
        "import random\r\n",
        "\r\n",
        "# starting words\r\n",
        "text = [\"today\", \"the\"]\r\n",
        "sentence_finished = False\r\n",
        " \r\n",
        "while not sentence_finished:\r\n",
        "  # select a random probability threshold  \r\n",
        "  r = random.random()\r\n",
        "  accumulator = .0\r\n",
        "\r\n",
        "  for word in model[tuple(text[-2:])].keys():\r\n",
        "      accumulator += model[tuple(text[-2:])][word]\r\n",
        "      # select words that are above the probability threshold\r\n",
        "      if accumulator >= r:\r\n",
        "          text.append(word)\r\n",
        "          break\r\n",
        "\r\n",
        "  if text[-2:] == [None, None]:\r\n",
        "      sentence_finished = True\r\n",
        " \r\n",
        "print (' '.join([t for t in text if t]))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "today the emirate ' s outlook for an accord signed in July to be a one shot deal ,\" is a waste management companies ,\" Willard Brown , along with 1 , 059 , 000 dlrs gain from June 1986 sale contract had included a 2 . 6 mln riyals from its own account .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn2F9p8t1lQV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}