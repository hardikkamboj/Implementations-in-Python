{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a41bd3-30e9-409e-96f6-289aa9ad7a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de1a02-94d9-45bd-8089-cdae5bb34e82",
   "metadata": {},
   "source": [
    "# Convolution from scratch \n",
    "\n",
    "- Basic convolution: same size array and kernel\n",
    "- Image Convolution: No stride and no padding\n",
    "- Convolution with padding\n",
    "- Convolution with stride and padding\n",
    "- Multi - channel convlution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1325a-91ca-489c-8746-f1dc43aee222",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basic convolution: Same size array and kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35deef6c-7fb7-48ab-a37d-b5ec913f66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_basic(input_array, kernel):\n",
    "    \"\"\"\n",
    "    Most basic convolution: element-wise multiplication and sum\n",
    "    Input array and kernel must have the same size\n",
    "    \n",
    "    Args:\n",
    "        input_array: 2D numpy array\n",
    "        kernel: 2D numpy array (same size as input_array)\n",
    "    \n",
    "    Returns:\n",
    "        Single scalar value (sum of element-wise multiplication)\n",
    "    \"\"\"\n",
    "    if input_array.shape != kernel.shape:\n",
    "        raise ValueError(f\"Input shape {input_array.shape} must match kernel shape {kernel.shape}\")\n",
    "    \n",
    "    # Element-wise multiplication and sum\n",
    "    result = np.sum(input_array * kernel)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e4fde7-684a-4cf1-a0af-c41a96b64f24",
   "metadata": {},
   "source": [
    "Test the above defined function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15571c74-f2c7-4a94-a44e-8e0054908eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input patch:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "Kernel:\n",
      "[[ 1  0 -1]\n",
      " [ 1  0 -1]\n",
      " [ 1  0 -1]]\n",
      "\n",
      "Convolution result: -6\n",
      "This is just: sum of (input * kernel element-wise)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create simple 3x3 input and kernel\n",
    "input_patch = np.array([[1, 2, 3],\n",
    "                       [4, 5, 6], \n",
    "                       [7, 8, 9]])\n",
    "\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                  [1, 0, -1],\n",
    "                  [1, 0, -1]])  # Vertical edge detector\n",
    "\n",
    "result = conv_basic(input_patch, kernel)\n",
    "\n",
    "print(\"Input patch:\")\n",
    "print(input_patch)\n",
    "print(\"\\nKernel:\")\n",
    "print(kernel)\n",
    "print(f\"\\nConvolution result: {result}\")\n",
    "print(\"This is just: sum of (input * kernel element-wise)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5681c-ea28-4d4c-9fc7-19a29e18ce00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Image Convolution - No Stride, No Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03bc238f-2e3f-4d65-b2ed-513e53d28a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_image_basic(image, kernel):\n",
    "    \"\"\"\n",
    "    Convolution on a 2D image with a smaller kernel\n",
    "    No stride (stride=1), no padding\n",
    "    \n",
    "    Args:\n",
    "        image: 2D numpy array (height, width)\n",
    "        kernel: 2D numpy array (smaller than image)\n",
    "    \n",
    "    Returns:\n",
    "        2D numpy array (convolved output)\n",
    "    \"\"\"\n",
    "    img_h, img_w = image.shape\n",
    "    ker_h, ker_w = kernel.shape\n",
    "    \n",
    "    # Calculate output dimensions\n",
    "    # the complete formula is [(Wâˆ’K+2P)/S]+1 \n",
    "    # in this case, P = S = 0 \n",
    "    out_h = img_h - ker_h + 1\n",
    "    out_w = img_w - ker_w + 1\n",
    "    \n",
    "    # Initialize output\n",
    "    output = np.zeros((out_h, out_w))\n",
    "    \n",
    "    # Slide kernel over image\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            # Extract patch from image\n",
    "            patch = image[i:i+ker_h, j:j+ker_w]\n",
    "            # Use our basic convolution function\n",
    "            output[i, j] = conv_basic(patch, kernel)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ff09b-fdec-407f-9b05-dd7906438a86",
   "metadata": {},
   "source": [
    "Test the above defined function, and compare it's results with pytorch implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f30bf178-3888-468a-9d8c-a7e13110eb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image (5x5):\n",
      "[[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]\n",
      " [11 12 13 14 15]\n",
      " [16 17 18 19 20]\n",
      " [21 22 23 24 25]]\n",
      "\n",
      "Kernel (3x3):\n",
      "[[ 1  0 -1]\n",
      " [ 1  0 -1]\n",
      " [ 1  0 -1]]\n",
      "\n",
      "Output shape: (3, 3) (expected: (3, 3))\n",
      "Output:\n",
      "[[-6. -6. -6.]\n",
      " [-6. -6. -6.]\n",
      " [-6. -6. -6.]]\n",
      "\n",
      "PyTorch result:\n",
      "[[-6. -6. -6.]\n",
      " [-6. -6. -6.]\n",
      " [-6. -6. -6.]]\n",
      "Results match: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a simple 5x5 image (you can also use a real image) \n",
    "image = np.array([[1, 2, 3, 4, 5],\n",
    "                 [6, 7, 8, 9, 10],\n",
    "                 [11, 12, 13, 14, 15],\n",
    "                 [16, 17, 18, 19, 20],\n",
    "                 [21, 22, 23, 24, 25]])\n",
    "\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                  [1, 0, -1],\n",
    "                  [1, 0, -1]])\n",
    "\n",
    "result = conv_image_basic(image, kernel)\n",
    "\n",
    "print(\"Input image (5x5):\")\n",
    "print(image)\n",
    "print(f\"\\nKernel (3x3):\")\n",
    "print(kernel)\n",
    "print(f\"\\nOutput shape: {result.shape} (expected: {(5-3+1, 5-3+1)})\")\n",
    "print(\"Output:\")\n",
    "print(result)\n",
    "\n",
    "# Verify with PyTorch\n",
    "image_torch = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "kernel_torch = torch.from_numpy(kernel).float().unsqueeze(0).unsqueeze(0)\n",
    "torch_result = F.conv2d(image_torch, kernel_torch).squeeze().numpy()\n",
    "\n",
    "print(f\"\\nPyTorch result:\")\n",
    "print(torch_result)\n",
    "print(f\"Results match: {np.allclose(result, torch_result)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac1a859-f843-46d2-87d6-215625da4a64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Convolution with padding\n",
    "\n",
    "Just add padding to the image, and use the previous function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e477f11d-6b58-4752-a4bc-90528842178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_image_with_padding(image, kernel, padding=0):\n",
    "    \"\"\"\n",
    "    Convolution on a 2D image with padding\n",
    "    No stride (stride=1)\n",
    "    \n",
    "    Args:\n",
    "        image: 2D numpy array (height, width)\n",
    "        kernel: 2D numpy array \n",
    "        padding: int (padding size)\n",
    "    \n",
    "    Returns:\n",
    "        2D numpy array (convolved output)\n",
    "    \"\"\"\n",
    "    # Add padding to image\n",
    "    if padding > 0:\n",
    "        padded_image = np.pad(image, padding, mode='constant', constant_values=0)\n",
    "    else:\n",
    "        padded_image = image\n",
    "    \n",
    "    # Now use our level 2 function on padded image\n",
    "    return conv_image_basic(padded_image, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6eeb9bf-92fe-4e7c-9c8f-e25da579b092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image (4x4):\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "\n",
      "Kernel (3x3):\n",
      "[[ 1  0 -1]\n",
      " [ 2  0 -2]\n",
      " [ 1  0 -1]]\n",
      "\n",
      "With padding=0:\n",
      "Output shape: (2, 2)\n",
      "Output:\n",
      "[[-8. -8.]\n",
      " [-8. -8.]]\n",
      "PyTorch matches: True\n",
      "\n",
      "With padding=1:\n",
      "Padded image shape: (6, 6)\n",
      "Output shape: (4, 4)\n",
      "Output:\n",
      "[[-10.  -6.  -6.  13.]\n",
      " [-24.  -8.  -8.  28.]\n",
      " [-40.  -8.  -8.  44.]\n",
      " [-38.  -6.  -6.  41.]]\n",
      "PyTorch matches: True\n",
      "\n",
      "With padding=2:\n",
      "Padded image shape: (8, 8)\n",
      "Output shape: (6, 6)\n",
      "Output:\n",
      "[[ -1.  -2.  -2.  -2.   3.   4.]\n",
      " [ -7. -10.  -6.  -6.  13.  16.]\n",
      " [-20. -24.  -8.  -8.  28.  32.]\n",
      " [-36. -40.  -8.  -8.  44.  48.]\n",
      " [-35. -38.  -6.  -6.  41.  44.]\n",
      " [-13. -14.  -2.  -2.  15.  16.]]\n",
      "PyTorch matches: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a simple 4x4 image\n",
    "image = np.array([[1, 2, 3, 4],\n",
    "                 [5, 6, 7, 8],\n",
    "                 [9, 10, 11, 12],\n",
    "                 [13, 14, 15, 16]])\n",
    "\n",
    "# 3x3 kernel\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                  [2, 0, -2],\n",
    "                  [1, 0, -1]])  # Sobel X\n",
    "\n",
    "print(\"Input image (4x4):\")\n",
    "print(image)\n",
    "print(f\"\\nKernel (3x3):\")\n",
    "print(kernel)\n",
    "\n",
    "# Test different padding values\n",
    "for pad in [0, 1, 2]:\n",
    "    result = conv_image_with_padding(image, kernel, padding=pad)\n",
    "    \n",
    "    print(f\"\\nWith padding={pad}:\")\n",
    "    if pad > 0:\n",
    "        padded = np.pad(image, pad, mode='constant', constant_values=0)\n",
    "        print(f\"Padded image shape: {padded.shape}\")\n",
    "    print(f\"Output shape: {result.shape}\")\n",
    "    print(\"Output:\")\n",
    "    print(result)\n",
    "    \n",
    "    # Verify with PyTorch\n",
    "    image_torch = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)\n",
    "    kernel_torch = torch.from_numpy(kernel).float().unsqueeze(0).unsqueeze(0)\n",
    "    torch_result = F.conv2d(image_torch, kernel_torch, padding=pad).squeeze().numpy()\n",
    "    \n",
    "    print(f\"PyTorch matches: {np.allclose(result, torch_result)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a20de0-80a8-4299-aa83-d12caa1e065e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Convlution with stride and padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b4814c6-519d-498a-a521-41d169153a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_image_full(image, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Full convolution implementation with stride and padding\n",
    "    \n",
    "    Args:\n",
    "        image: 2D numpy array (height, width)\n",
    "        kernel: 2D numpy array\n",
    "        stride: int (stride size)\n",
    "        padding: int (padding size)\n",
    "    \n",
    "    Returns:\n",
    "        2D numpy array (convolved output)\n",
    "    \"\"\"\n",
    "    # Add padding to image\n",
    "    if padding > 0:\n",
    "        padded_image = np.pad(image, padding, mode='constant', constant_values=0)\n",
    "    else:\n",
    "        padded_image = image\n",
    "    \n",
    "    img_h, img_w = padded_image.shape\n",
    "    ker_h, ker_w = kernel.shape\n",
    "    \n",
    "    # Calculate output dimensions with stride\n",
    "    # padding information has already been added \n",
    "    out_h = (img_h - ker_h) // stride + 1\n",
    "    out_w = (img_w - ker_w) // stride + 1\n",
    "    \n",
    "    # Initialize output\n",
    "    output = np.zeros((out_h, out_w))\n",
    "    \n",
    "    # Slide kernel over image with stride\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            # Calculate position with stride\n",
    "            # there's also a different way to implement this in for loop\n",
    "            start_i = i * stride\n",
    "            start_j = j * stride\n",
    "            \n",
    "            # Extract patch from image\n",
    "            patch = padded_image[start_i:start_i+ker_h, start_j:start_j+ker_w]\n",
    "            # Use our basic convolution function\n",
    "            output[i, j] = conv_basic(patch, kernel)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "666a1efe-f2ba-4e8b-a580-ded5e75108d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image (6x6):\n",
      "[[4 6 3 7 7 7]\n",
      " [9 0 5 3 3 7]\n",
      " [5 8 3 9 4 2]\n",
      " [8 7 9 4 7 3]\n",
      " [1 2 7 7 0 8]\n",
      " [9 2 1 8 0 1]]\n",
      "\n",
      "Kernel (3x3):\n",
      "[[ 1  1  1]\n",
      " [ 0  0  0]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "Stride=1, Padding=0:\n",
      "Output shape: (4, 4)\n",
      "Output:\n",
      "[[ -3.  -4.   1.   6.]\n",
      " [-10. -12.  -9.  -1.]\n",
      " [  6.   4.   2.   0.]\n",
      " [ 12.   9.  11.   5.]]\n",
      "PyTorch matches: True\n",
      "\n",
      "Stride=1, Padding=1:\n",
      "Output shape: (6, 6)\n",
      "Output:\n",
      "[[ -9. -14.  -8. -11. -13. -10.]\n",
      " [ -3.  -3.  -4.   1.   6.   8.]\n",
      " [ -6. -10. -12.  -9.  -1.   0.]\n",
      " [ 10.   6.   4.   2.   0.  -2.]\n",
      " [  4.  12.   9.  11.   5.   9.]\n",
      " [  3.  10.  16.  14.  15.   8.]]\n",
      "PyTorch matches: True\n",
      "\n",
      "Stride=2, Padding=0:\n",
      "Output shape: (2, 2)\n",
      "Output:\n",
      "[[-3.  1.]\n",
      " [ 6.  2.]]\n",
      "PyTorch matches: True\n",
      "\n",
      "Stride=2, Padding=1:\n",
      "Output shape: (3, 3)\n",
      "Output:\n",
      "[[ -9.  -8. -13.]\n",
      " [ -6. -12.  -1.]\n",
      " [  4.   9.   5.]]\n",
      "PyTorch matches: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a 6x6 image\n",
    "image = np.random.randint(0, 10, (6, 6))\n",
    "\n",
    "# 3x3 kernel\n",
    "kernel = np.array([[1, 1, 1],\n",
    "                  [0, 0, 0],\n",
    "                  [-1, -1, -1]])\n",
    "\n",
    "print(\"Input image (6x6):\")\n",
    "print(image)\n",
    "print(f\"\\nKernel (3x3):\")\n",
    "print(kernel)\n",
    "\n",
    "# Test different combinations\n",
    "test_configs = [\n",
    "    {\"stride\": 1, \"padding\": 0},\n",
    "    {\"stride\": 1, \"padding\": 1},\n",
    "    {\"stride\": 2, \"padding\": 0},\n",
    "    {\"stride\": 2, \"padding\": 1},\n",
    "]\n",
    "\n",
    "for config in test_configs:\n",
    "    stride = config[\"stride\"]\n",
    "    padding = config[\"padding\"]\n",
    "    \n",
    "    result = conv_image_full(image, kernel, stride=stride, padding=padding)\n",
    "    \n",
    "    print(f\"\\nStride={stride}, Padding={padding}:\")\n",
    "    print(f\"Output shape: {result.shape}\")\n",
    "    print(\"Output:\")\n",
    "    print(result)\n",
    "    \n",
    "    # Verify with PyTorch\n",
    "    image_torch = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)\n",
    "    kernel_torch = torch.from_numpy(kernel).float().unsqueeze(0).unsqueeze(0)\n",
    "    torch_result = F.conv2d(image_torch, kernel_torch, \n",
    "                           stride=stride, padding=padding).squeeze().numpy()\n",
    "    \n",
    "    print(f\"PyTorch matches: {np.allclose(result, torch_result)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c5b9dc-d668-40fe-a88f-3c8c4b12a9b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Multi Channel Convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c902104-9dae-4080-801c-7546547791bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18bda9fd-131b-4f81-bf5a-dd0b43008c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_full(input_tensor, kernel, bias=None, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Full 2D convolution with multiple channels, batches, stride, and padding\n",
    "    \n",
    "    Args:\n",
    "        input_tensor: 4D numpy array (batch_size, in_channels, height, width)\n",
    "        kernel: 4D numpy array (out_channels, in_channels, kernel_height, kernel_width)\n",
    "        bias: 1D numpy array (out_channels,) or None\n",
    "        stride: int\n",
    "        padding: int\n",
    "    \n",
    "    Returns:\n",
    "        4D numpy array (batch_size, out_channels, out_height, out_width)\n",
    "    \"\"\"\n",
    "    batch_size, in_channels, input_h, input_w = input_tensor.shape\n",
    "    out_channels, _, kernel_h, kernel_w = kernel.shape\n",
    "    \n",
    "    # Add padding to input\n",
    "    if padding > 0:\n",
    "        padded_input = np.pad(input_tensor, \n",
    "                             ((0, 0), (0, 0), (padding, padding), (padding, padding)),\n",
    "                             mode='constant', constant_values=0)\n",
    "    else:\n",
    "        padded_input = input_tensor\n",
    "    \n",
    "    _, _, padded_h, padded_w = padded_input.shape\n",
    "    \n",
    "    # Calculate output dimensions\n",
    "    output_h = (padded_h - kernel_h) // stride + 1\n",
    "    output_w = (padded_w - kernel_w) // stride + 1\n",
    "    \n",
    "    # Initialize output tensor\n",
    "    output = np.zeros((batch_size, out_channels, output_h, output_w))\n",
    "    \n",
    "    # Perform convolution\n",
    "    for b in range(batch_size):\n",
    "        for oc in range(out_channels):\n",
    "            for oh in range(output_h):\n",
    "                for ow in range(output_w):\n",
    "                    # Calculate input region with stride\n",
    "                    h_start = oh * stride\n",
    "                    h_end = h_start + kernel_h\n",
    "                    w_start = ow * stride\n",
    "                    w_end = w_start + kernel_w\n",
    "                    \n",
    "                    # Extract input patch (all input channels)\n",
    "                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]\n",
    "                    \n",
    "                    # Compute convolution: sum over all input channels\n",
    "                    conv_result = 0\n",
    "                    for ic in range(in_channels):\n",
    "                        # Use our basic convolution function for each channel\n",
    "                        conv_result += conv_basic(input_patch[ic], kernel[oc, ic])\n",
    "                    \n",
    "                    output[b, oc, oh, ow] = conv_result\n",
    "                    \n",
    "                    # Add bias if provided\n",
    "                    if bias is not None:\n",
    "                        output[b, oc, oh, ow] += bias[oc]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75df8a7d-1335-403a-a1c7-cb2604db4aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2, 3, 6, 6)\n",
      "Kernel shape: (2, 3, 3, 3)\n",
      "Bias shape: (2,)\n",
      "\n",
      "Our result shape: (2, 2, 6, 6)\n",
      "PyTorch result shape: (2, 2, 6, 6)\n",
      "Max difference (after rounding to 6 decimals): 2.33e-06\n",
      "Results match (after rounding): True\n",
      "Raw max difference (before rounding): 2.26e-06\n",
      "Raw results match: True\n"
     ]
    }
   ],
   "source": [
    "# to get good results, I had to round off some values. \n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create test data\n",
    "batch_size, in_channels, height, width = 2, 3, 6, 6\n",
    "out_channels, kernel_h, kernel_w = 2, 3, 3\n",
    "\n",
    "input_tensor = np.random.randn(batch_size, in_channels, height, width).astype(np.float32)\n",
    "kernel = np.random.randn(out_channels, in_channels, kernel_h, kernel_w).astype(np.float32)\n",
    "bias = np.random.randn(out_channels).astype(np.float32)\n",
    "\n",
    "print(f\"Input shape: {input_tensor.shape}\")\n",
    "print(f\"Kernel shape: {kernel.shape}\")\n",
    "print(f\"Bias shape: {bias.shape}\")\n",
    "\n",
    "# Test our implementation\n",
    "result = conv2d_full(input_tensor, kernel, bias, stride=1, padding=1)\n",
    "\n",
    "# Compare with PyTorch\n",
    "input_torch = torch.from_numpy(input_tensor)\n",
    "kernel_torch = torch.from_numpy(kernel)\n",
    "bias_torch = torch.from_numpy(bias)\n",
    "torch_result = F.conv2d(input_torch, kernel_torch, bias_torch, \n",
    "                       stride=1, padding=1).numpy()\n",
    "\n",
    "print(f\"\\nOur result shape: {result.shape}\")\n",
    "print(f\"PyTorch result shape: {torch_result.shape}\")\n",
    "\n",
    "# Round both results to handle floating point precision issues\n",
    "result_rounded = np.round(result, decimals=6)\n",
    "torch_result_rounded = np.round(torch_result, decimals=6)\n",
    "\n",
    "# Calculate difference on rounded values\n",
    "max_diff = np.max(np.abs(result_rounded - torch_result_rounded))\n",
    "results_match = np.allclose(result_rounded, torch_result_rounded, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "print(f\"Max difference (after rounding to 6 decimals): {max_diff:.2e}\")\n",
    "print(f\"Results match (after rounding): {results_match}\")\n",
    "\n",
    "# Also show raw comparison for reference\n",
    "raw_max_diff = np.max(np.abs(result - torch_result))\n",
    "print(f\"Raw max difference (before rounding): {raw_max_diff:.2e}\")\n",
    "print(f\"Raw results match: {np.allclose(result, torch_result, rtol=1e-5, atol=1e-6)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97d17c-1e59-40d5-8893-7cfc95ccf371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95c1c9e4-e207-40c6-97f1-455e408245d6",
   "metadata": {},
   "source": [
    "# Maxpooling from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4c254-3fc4-40e7-b044-34315e19b766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76c1956f-ec45-4fa8-bb50-cecd6854d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_basic(input_array):\n",
    "    \"\"\"\n",
    "    Most basic max pooling: find maximum value in an array\n",
    "    \n",
    "    Args:\n",
    "        input_array: 2D numpy array\n",
    "    \n",
    "    Returns:\n",
    "        Single scalar value (maximum in the array)\n",
    "    \"\"\"\n",
    "    return np.max(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc47f3bf-3187-4788-b695-2c72a0f087ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_image_basic(image, pool_size):\n",
    "    \"\"\"\n",
    "    Max pooling on a 2D image with a pooling window\n",
    "    Non-overlapping pooling (stride = pool_size)\n",
    "    \n",
    "    Args:\n",
    "        image: 2D numpy array (height, width)\n",
    "        pool_size: int or tuple (pooling window size)\n",
    "    \n",
    "    Returns:\n",
    "        2D numpy array (max pooled output)\n",
    "    \"\"\"\n",
    "    if isinstance(pool_size, int):\n",
    "        pool_h, pool_w = pool_size, pool_size\n",
    "    else:\n",
    "        pool_h, pool_w = pool_size\n",
    "    \n",
    "    img_h, img_w = image.shape\n",
    "    \n",
    "    # Calculate output dimensions (non-overlapping pooling)\n",
    "    out_h = img_h // pool_h\n",
    "    out_w = img_w // pool_w\n",
    "    \n",
    "    # Initialize output\n",
    "    output = np.zeros((out_h, out_w))\n",
    "    \n",
    "    # Apply max pooling\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            # Extract patch from image (non-overlapping)\n",
    "            start_i = i * pool_h\n",
    "            start_j = j * pool_w\n",
    "            patch = image[start_i:start_i+pool_h, start_j:start_j+pool_w]\n",
    "            # Use our basic max function\n",
    "            output[i, j] = maxpool_basic(patch)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b388bdda-6554-4b04-9427-9dd03183fc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image (4x4):\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "\n",
      "Pool size: 2x2\n",
      "Output shape: (2, 2) (expected: (2, 2))\n",
      "Output:\n",
      "[[ 6.  8.]\n",
      " [14. 16.]]\n",
      "\n",
      "PyTorch result:\n",
      "[[ 6.  8.]\n",
      " [14. 16.]]\n",
      "Results match: True\n",
      "\n",
      "\n",
      "Test with 6x6 image:\n",
      "[[ 9  7  4 18 13 11]\n",
      " [ 4  4 10  5  9  3]\n",
      " [17  3 16  4 18 17]\n",
      " [ 7  5 12 17 13  3]\n",
      " [ 9 17 17 16 13 19]\n",
      " [17  4 12  9 19 12]]\n",
      "\n",
      "Pool size: 2x2\n",
      "Output shape: (3, 3)\n",
      "Output:\n",
      "[[ 9. 18. 13.]\n",
      " [17. 17. 18.]\n",
      " [17. 17. 19.]]\n",
      "\n",
      "Pool size: 3x3\n",
      "Output shape: (2, 2)\n",
      "Output:\n",
      "[[17. 18.]\n",
      " [17. 19.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a simple 4x4 image\n",
    "image = np.array([[1, 2, 3, 4],\n",
    "                 [5, 6, 7, 8],\n",
    "                 [9, 10, 11, 12],\n",
    "                 [13, 14, 15, 16]])\n",
    "\n",
    "print(\"Input image (4x4):\")\n",
    "print(image)\n",
    "\n",
    "# Test 2x2 pooling\n",
    "result_2x2 = maxpool_image_basic(image, pool_size=2)\n",
    "print(f\"\\nPool size: 2x2\")\n",
    "print(f\"Output shape: {result_2x2.shape} (expected: {(4//2, 4//2)})\")\n",
    "print(\"Output:\")\n",
    "print(result_2x2)\n",
    "\n",
    "# Verify with PyTorch\n",
    "image_torch = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)\n",
    "torch_result = F.max_pool2d(image_torch, kernel_size=2, stride=2).squeeze().numpy()\n",
    "\n",
    "print(f\"\\nPyTorch result:\")\n",
    "print(torch_result)\n",
    "print(f\"Results match: {np.allclose(result_2x2, torch_result)}\")\n",
    "\n",
    "# Test with 6x6 image and different pool sizes\n",
    "image_6x6 = np.random.randint(1, 20, (6, 6))\n",
    "print(f\"\\n\\nTest with 6x6 image:\")\n",
    "print(image_6x6)\n",
    "\n",
    "for pool_size in [2, 3]:\n",
    "    result = maxpool_image_basic(image_6x6, pool_size)\n",
    "    print(f\"\\nPool size: {pool_size}x{pool_size}\")\n",
    "    print(f\"Output shape: {result.shape}\")\n",
    "    print(\"Output:\")\n",
    "    print(result)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76b291dd-70c7-4dd0-94ee-678af8ff7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_image_with_stride(image, pool_size, stride=None, padding=0):\n",
    "    \"\"\"\n",
    "    Max pooling with custom stride\n",
    "    \n",
    "    Args:\n",
    "        image: 2D numpy array (height, width)\n",
    "        pool_size: int or tuple (pooling window size)\n",
    "        stride: int or tuple (stride size). If None, defaults to pool_size\n",
    "        padding: int (padding size)\n",
    "    \n",
    "    Returns:\n",
    "        2D numpy array (max pooled output)\n",
    "    \"\"\"\n",
    "    if isinstance(pool_size, int):\n",
    "        pool_h, pool_w = pool_size, pool_size\n",
    "    else:\n",
    "        pool_h, pool_w = pool_size\n",
    "    \n",
    "    if stride is None:\n",
    "        stride_h, stride_w = pool_h, pool_w\n",
    "    elif isinstance(stride, int):\n",
    "        stride_h, stride_w = stride, stride\n",
    "    else:\n",
    "        stride_h, stride_w = stride\n",
    "    \n",
    "    # Add padding to image\n",
    "    if padding > 0:\n",
    "        padded_image = np.pad(image, padding, mode='constant', constant_values=0) # could be an issue if image has negative values \n",
    "    else:\n",
    "        padded_image = image\n",
    "    \n",
    "    img_h, img_w = padded_image.shape\n",
    "    \n",
    "    # Calculate output dimensions with custom stride\n",
    "    out_h = (img_h - pool_h) // stride_h + 1\n",
    "    out_w = (img_w - pool_w) // stride_w + 1\n",
    "    \n",
    "    # Initialize output\n",
    "    output = np.zeros((out_h, out_w))\n",
    "    \n",
    "    # Apply max pooling with stride\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            # Calculate position with stride\n",
    "            start_i = i * stride_h\n",
    "            start_j = j * stride_w\n",
    "            \n",
    "            # Extract patch from image\n",
    "            patch = padded_image[start_i:start_i+pool_h, start_j:start_j+pool_w]\n",
    "            # Use our basic max function\n",
    "            output[i, j] = maxpool_basic(patch)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9439574c-ab15-482f-b906-ed51757d76c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAXPOOL LEVEL 4: MaxPool with Custom Stride\n",
      "============================================================\n",
      "Input image (6x6):\n",
      "[[ 5  5  6 19  8 16]\n",
      " [13  1 17  7 13  4]\n",
      " [ 4  6 19 12  7 10]\n",
      " [19  7  3 13 13 18]\n",
      " [ 8  9  7  1  3 13]\n",
      " [17  1  6  6 12 13]]\n",
      "\n",
      "Pool_size=2, Stride=1, Padding=0:\n",
      "Output shape: (5, 5)\n",
      "Output:\n",
      "[[13. 17. 19. 19. 16.]\n",
      " [13. 19. 19. 13. 13.]\n",
      " [19. 19. 19. 13. 18.]\n",
      " [19.  9. 13. 13. 18.]\n",
      " [17.  9.  7. 12. 13.]]\n",
      "PyTorch result:\n",
      "[[13. 17. 19. 19. 16.]\n",
      " [13. 19. 19. 13. 13.]\n",
      " [19. 19. 19. 13. 18.]\n",
      " [19.  9. 13. 13. 18.]\n",
      " [17.  9.  7. 12. 13.]]\n",
      "PyTorch matches: True\n",
      "\n",
      "Pool_size=2, Stride=2, Padding=0:\n",
      "Output shape: (3, 3)\n",
      "Output:\n",
      "[[13. 19. 16.]\n",
      " [19. 19. 18.]\n",
      " [17.  7. 13.]]\n",
      "PyTorch result:\n",
      "[[13. 19. 16.]\n",
      " [19. 19. 18.]\n",
      " [17.  7. 13.]]\n",
      "PyTorch matches: True\n",
      "\n",
      "Pool_size=3, Stride=1, Padding=0:\n",
      "Output shape: (4, 4)\n",
      "Output:\n",
      "[[19. 19. 19. 19.]\n",
      " [19. 19. 19. 18.]\n",
      " [19. 19. 19. 18.]\n",
      " [19. 13. 13. 18.]]\n",
      "PyTorch result:\n",
      "[[19. 19. 19. 19.]\n",
      " [19. 19. 19. 18.]\n",
      " [19. 19. 19. 18.]\n",
      " [19. 13. 13. 18.]]\n",
      "PyTorch matches: True\n",
      "\n",
      "Pool_size=3, Stride=2, Padding=1:\n",
      "Output shape: (3, 3)\n",
      "Output:\n",
      "[[13. 19. 19.]\n",
      " [19. 19. 18.]\n",
      " [19. 13. 18.]]\n",
      "PyTorch result:\n",
      "[[13. 19. 19.]\n",
      " [19. 19. 18.]\n",
      " [19. 13. 18.]]\n",
      "PyTorch matches: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test max pooling with custom stride\"\"\"\n",
    "print(\"MAXPOOL LEVEL 4: MaxPool with Custom Stride\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a 6x6 image\n",
    "image = np.random.randint(1, 20, (6, 6))\n",
    "\n",
    "print(\"Input image (6x6):\")\n",
    "print(image)\n",
    "\n",
    "# Test different combinations\n",
    "test_configs = [\n",
    "    {\"pool_size\": 2, \"stride\": 1, \"padding\": 0},\n",
    "    {\"pool_size\": 2, \"stride\": 2, \"padding\": 0},  # Non-overlapping\n",
    "    {\"pool_size\": 3, \"stride\": 1, \"padding\": 0},  # Overlapping\n",
    "    {\"pool_size\": 3, \"stride\": 2, \"padding\": 1},\n",
    "]\n",
    "\n",
    "for config in test_configs:\n",
    "    pool_size = config[\"pool_size\"]\n",
    "    stride = config[\"stride\"]\n",
    "    padding = config[\"padding\"]\n",
    "    \n",
    "    result = maxpool_image_with_stride(image, pool_size=pool_size, \n",
    "                                     stride=stride, padding=padding)\n",
    "    \n",
    "    print(f\"\\nPool_size={pool_size}, Stride={stride}, Padding={padding}:\")\n",
    "    print(f\"Output shape: {result.shape}\")\n",
    "    print(\"Output:\")\n",
    "    print(result)\n",
    "    \n",
    "    # Verify with PyTorch\n",
    "    image_torch = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)\n",
    "    torch_result = F.max_pool2d(image_torch, kernel_size=pool_size, \n",
    "                               stride=stride, padding=padding).squeeze().numpy()\n",
    "    \n",
    "    print(f\"PyTorch result:\")\n",
    "    print(torch_result)\n",
    "    print(f\"PyTorch matches: {np.allclose(result, torch_result)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8259839d-9de2-4b3a-992d-3bec599f6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d_full(input_tensor, pool_size, stride=None, padding=0):\n",
    "    \"\"\"\n",
    "    Full 2D max pooling with multiple channels and batches\n",
    "    \n",
    "    Args:\n",
    "        input_tensor: 4D numpy array (batch_size, channels, height, width)\n",
    "        pool_size: int or tuple (pooling window size)\n",
    "        stride: int, tuple, or None (stride size)\n",
    "        padding: int (padding size)\n",
    "    \n",
    "    Returns:\n",
    "        4D numpy array (batch_size, channels, out_height, out_width)\n",
    "    \"\"\"\n",
    "    if isinstance(pool_size, int):\n",
    "        pool_h, pool_w = pool_size, pool_size\n",
    "    else:\n",
    "        pool_h, pool_w = pool_size\n",
    "    \n",
    "    if stride is None:\n",
    "        stride_h, stride_w = pool_h, pool_w\n",
    "    elif isinstance(stride, int):\n",
    "        stride_h, stride_w = stride, stride\n",
    "    else:\n",
    "        stride_h, stride_w = stride\n",
    "    \n",
    "    batch_size, channels, input_h, input_w = input_tensor.shape\n",
    "    \n",
    "    # Add padding to input\n",
    "    if padding > 0:\n",
    "        padded_input = np.pad(input_tensor,\n",
    "                             ((0, 0), (0, 0), (padding, padding), (padding, padding)),\n",
    "                             mode='constant', constant_values=-np.inf)\n",
    "    else:\n",
    "        padded_input = input_tensor\n",
    "    \n",
    "    _, _, padded_h, padded_w = padded_input.shape\n",
    "    \n",
    "    # Calculate output dimensions\n",
    "    output_h = (padded_h - pool_h) // stride_h + 1\n",
    "    output_w = (padded_w - pool_w) // stride_w + 1\n",
    "    \n",
    "    # Initialize output tensor\n",
    "    output = np.zeros((batch_size, channels, output_h, output_w))\n",
    "    \n",
    "    # Perform max pooling\n",
    "    for b in range(batch_size):\n",
    "        for c in range(channels):\n",
    "            for oh in range(output_h):\n",
    "                for ow in range(output_w):\n",
    "                    # Calculate input region with stride\n",
    "                    h_start = oh * stride_h\n",
    "                    h_end = h_start + pool_h\n",
    "                    w_start = ow * stride_w\n",
    "                    w_end = w_start + pool_w\n",
    "                    \n",
    "                    # Extract input patch for this channel\n",
    "                    input_patch = padded_input[b, c, h_start:h_end, w_start:w_end]\n",
    "                    \n",
    "                    # Use our basic max function\n",
    "                    output[b, c, oh, ow] = maxpool_basic(input_patch)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f9b166d-0a78-4a9b-a6d4-1d095ea1711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAXPOOL LEVEL 5: Full Multi-Channel MaxPool\n",
      "============================================================\n",
      "Input shape: (2, 3, 8, 8)\n",
      "\n",
      "Testing: 2x2 pool, stride=2, no padding\n",
      "----------------------------------------\n",
      "Our result shape: (2, 3, 4, 4)\n",
      "PyTorch result shape: (2, 3, 4, 4)\n",
      "Max difference (after rounding to 6 decimals): 1.03e-06\n",
      "Results match (after rounding): True\n",
      "Raw max difference (before rounding): 0.00e+00\n",
      "Raw results match: True\n",
      "\n",
      "Testing: 2x2 pool, stride=1, no padding\n",
      "----------------------------------------\n",
      "Our result shape: (2, 3, 7, 7)\n",
      "PyTorch result shape: (2, 3, 7, 7)\n",
      "Max difference (after rounding to 6 decimals): 1.03e-06\n",
      "Results match (after rounding): True\n",
      "Raw max difference (before rounding): 0.00e+00\n",
      "Raw results match: True\n",
      "\n",
      "Testing: 3x3 pool, stride=2, padding=1\n",
      "----------------------------------------\n",
      "Our result shape: (2, 3, 4, 4)\n",
      "PyTorch result shape: (2, 3, 4, 4)\n",
      "Max difference (after rounding to 6 decimals): 1.03e-06\n",
      "Results match (after rounding): True\n",
      "Raw max difference (before rounding): 0.00e+00\n",
      "Raw results match: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test full multi-channel max pooling\"\"\"\n",
    "print(\"MAXPOOL LEVEL 5: Full Multi-Channel MaxPool\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create test data\n",
    "batch_size, channels, height, width = 2, 3, 8, 8\n",
    "\n",
    "input_tensor = np.random.randn(batch_size, channels, height, width).astype(np.float32)\n",
    "\n",
    "print(f\"Input shape: {input_tensor.shape}\")\n",
    "\n",
    "# Test different configurations\n",
    "test_configs = [\n",
    "    {\"pool_size\": 2, \"stride\": 2, \"padding\": 0, \"name\": \"2x2 pool, stride=2, no padding\"},\n",
    "    {\"pool_size\": 2, \"stride\": 1, \"padding\": 0, \"name\": \"2x2 pool, stride=1, no padding\"},  \n",
    "    {\"pool_size\": 3, \"stride\": 2, \"padding\": 1, \"name\": \"3x3 pool, stride=2, padding=1\"},\n",
    "]\n",
    "\n",
    "for config in test_configs:\n",
    "    pool_size = config[\"pool_size\"]\n",
    "    stride = config[\"stride\"]\n",
    "    padding = config[\"padding\"]\n",
    "    name = config[\"name\"]\n",
    "    \n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Test our implementation\n",
    "    result = maxpool2d_full(input_tensor, pool_size=pool_size, \n",
    "                           stride=stride, padding=padding)\n",
    "    \n",
    "    # Compare with PyTorch\n",
    "    input_torch = torch.from_numpy(input_tensor)\n",
    "    torch_result = F.max_pool2d(input_torch, kernel_size=pool_size,\n",
    "                               stride=stride, padding=padding).numpy()\n",
    "    \n",
    "    print(f\"Our result shape: {result.shape}\")\n",
    "    print(f\"PyTorch result shape: {torch_result.shape}\")\n",
    "    \n",
    "    # Round both results to handle floating point precision issues\n",
    "    result_rounded = np.round(result, decimals=6)\n",
    "    torch_result_rounded = np.round(torch_result, decimals=6)\n",
    "    \n",
    "    # Calculate difference on rounded values\n",
    "    max_diff = np.max(np.abs(result_rounded - torch_result_rounded))\n",
    "    results_match = np.allclose(result_rounded, torch_result_rounded, rtol=1e-6, atol=1e-6)\n",
    "    \n",
    "    print(f\"Max difference (after rounding to 6 decimals): {max_diff:.2e}\")\n",
    "    print(f\"Results match (after rounding): {results_match}\")\n",
    "    \n",
    "    # Also show raw comparison for reference\n",
    "    raw_max_diff = np.max(np.abs(result - torch_result))\n",
    "    print(f\"Raw max difference (before rounding): {raw_max_diff:.2e}\")\n",
    "    print(f\"Raw results match: {np.allclose(result, torch_result, rtol=1e-5, atol=1e-6)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977442a-058b-4b30-8460-9cdcb018c83b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
